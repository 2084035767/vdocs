# 三、特征检测与描述

## 3.1 Harris角点检测



**什么是角点**

角点还没有明确的数学定义，但普遍具有以下特征：

1. 局部小窗口沿各方向移动，窗口内的像素均产生明显变化的点。
2. 图像局部曲率(梯度)突变的点。
3. 对于同一场景，即使视角发生变化，其角点通常具备某些稳定不变性质的特征



**角点检测算法的原始思想**

我们可以从角点具有的特征出发：即选取一个局部窗口，将这个窗口沿着各个方向移动，计算移动前后窗口内像素的差异的多少进而判断窗口对应的区域是否是角点。
$$
E(u,v)=\sum_{x,y} w(x,y)[I[x+u,y+v]-I(x,y)]^2
$$

- $E(u,v)$：能量函数，u和v体现窗口的移动。
- $w(x,y)$：窗口函数，每个像素差值乘上一个权重，体现对整体的贡献程度。中值滤波或高斯滤波。
- $[I[x+u,y+v]-I(x,y)]$：移动后与移动前的灰度差。



**Harris角点的特征**

- 平坦区域：任意方向移动动，无灰度变化
- 边缘：沿着边缘方向移，无灰度变化
- 角点：沿任意方向移动，明显灰度变化



**Harris角点检测**

Harris角点检测，由Chris Harris和Mike Stephens于1988年提出。该算法通过计算图像的局部灰度变化来检测角点，并利用协方差矩阵的特征值来确定是否为角点。

Harris角点的计算方法甚至不需要用到特征值，只需要计算一个**Harris响应值R**：
$$
R = detM-k(traceM)^2\\
detM=\lambda _1\lambda _2\\
traceM=\lambda _1+\lambda _2
$$


- R只与M的特征值有关
- 角点：R为大数值正数
- 边缘：R为大数值负数
- 平坦区：R为小数值



**矩阵M的特征值**

- **平坦区域**：两个特征值都小，且近似相等，能量函数在各个方向上都较小；
- **边缘区域**：一个特征值大，另一个特征值小，能量函数在某一方向上增大，其他方向较小；
- **角点区域**：两个特征值都大，且近似相等，能量函数在所有方向上都增大。



**Harris角点算法的基本步骤**

1. 计算窗口中各像素点在x和y方向的梯度；
2. 计算两个方向梯度的乘积,即$Ix ^ 2 , Iy ^ 2 , IxIy$(可以用一些一阶梯度算子求得图像梯度)
3. 使用滤波核对窗口中的每一像素进行加权，生成矩阵M和元素A，B，C
4. 计算每个像素的Harris响应值R，并对小于某阈值T的R置0；
5. 由于角点所在区域的一定邻域内都有可能被检测为角点，所以为了防止角点聚集，最后在3×33×3或5×55×5的邻域内进行非极大值抑制，局部最大值点即为图像中的角点。

`cv2.cornerHarris()`函数实现

```python
import cv2 
import numpy as np

# 导入图片
img = cv2.imread('test_1.jpg')
print ('img.shape:',img.shape)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
gray = np.float32(gray)#转换为float32格式
dst = cv2.cornerHarris(gray, 2, 3, 0.04)
print ('dst.shape:',dst.shape)

img.shape: (512, 512, 3)
dst.shape: (512, 512)
img[dst>0.01*dst.max()]=[0,0,255] #非极大值抑制,将边界点标红
cv2.imshow('dst',img) 
cv2.waitKey(0) 
cv2.destroyAllWindows()
```





## 3.2 SIFT特征检测与描述

**Scale Invariant Feature Transform（SIFT）** 是一种用于计算机视觉和图像处理中的特征检测和描述的算法，可以说是在计算机视觉一种非常流行和广泛使用的算法，它能够检测和描述图像中的关键点，并具有尺度、旋转和视角的不变性，适用于各种图像处理任务，例如目标识别、图像匹配、图像拼接等。SIFT算法主要包括：**尺度空间检测、特征关键点检测、特征描述**等，接下来我们来分别看一下这些概念

以下是对SIFT算法的详细介绍：

1. **特征点检测：**
   - 尺度空间极值检测：SIFT首先在不同尺度下使用高斯模糊滤波器构建尺度空间金字塔，然后通过比较每个像素与其周围像素及所处尺度上的像素进行检测，找到图像中的关键点。
   - 关键点精化：通过利用尺度空间的极值点，对关键点进行精化，计算其精确位置和尺度尺度，并根据梯度方向来确定主方向。
2. **特征描述：**
   - 局部图像描述子：以关键点为中心，在其周围的邻域内构建一个具有旋转不变性和尺度不变性的局部图像描述子。该描述子基于关键点附近的梯度方向和强度信息，通过生成一个特征向量来描述关键点周围的图像结构。
   - 方向直方图：在计算局部图像描述子之前，首先根据关键点周围的梯度方向计算一个方向直方图，用来确定主方向。
3. **特征匹配：**
   - 特征向量匹配：将两幅图像的特征向量进行匹配，通常使用最近邻匹配方法（如欧氏距离）来寻找每个特征点的最佳匹配。同时，还可以使用二次最近邻比率测试来过滤不可靠的匹配。
   - 健壮性和一致性：为了提高匹配的健壮性和一致性，可以使用诸如RANSAC（随机抽样一致性）等方法来剔除异常和错误的匹配点。

SIFT算法的关键优势在于其对尺度、旋转和视角的不变性，使得它能够在多种条件下健壮地检测和匹配图像中的特征点。此外，SIFT算法还具有以下特点：

- 独特性：SIFT特征是在图像中独一无二的，它们可以用来区分不同的图像区域。
- 不变性：SIFT特征对于有限的视角变化、尺度变化以及轻微的仿射变换都具有较好的不变性。
- 高健壮性：SIFT算法对于光照变化、噪声和部分遮挡等情况下仍能产生准确的匹配结果。
- 可扩展性：SIFT算法可以应用于各种图像尺寸和分辨率的图像，并且在大规模图像数据库中进行高效匹配。

因此在目标识别、图像匹配和图像拼接等应用中具有重要的作用。



图像尺度空间



我们知道在一定的范围内，无论物体是大还是小，我们人眼都可以分辨出来，然而计算机要有相同的能力却很难，所以要让机器能够对物体在不同尺度下有一个统一的认知，就需要考虑图像在不同的尺度下都存在的特点。

**图像尺度空间**是指在不同尺度下对图像进行分析和处理的一种表示方式。在图像尺度空间中，同一物体或结构的特征在不同尺度下具有不同的尺度信息。这是因为图像中的物体和结构可能以不同的尺度出现，例如大小、边缘和纹理等。通过在不同尺度下分析图像，我们可以获取更全面和健壮的特征表示，以适应不同尺度上的目标检测、识别和描述任务。

尺度空间的获取通常使用高斯模糊来实现



- **高斯金字塔**： 高斯金字塔是一种通过对图像进行连续的高斯滤波和下采样操作来构建图像尺度空间的方法。具体步骤如下：

  - 先对原始图像应用一个初始尺度的高斯滤波器。
  - 对滤波后的图像进行下采样（通常是进行二次减半），得到下一层金字塔图像。
  - 重复以上步骤，直到达到预定的尺度层数。

- **多分辨率金字塔**，它是通过将原始图像进行分解，得到一系列具有不同分辨率的图像层级，从而实现对图像的多尺度分析和处理通常采用逐步降采样（downsampling）和上采样（upsampling）的方法。

  - 首先，原始图像通过降采样操作被缩小为较低分辨率的图像，然后这个较低分辨率的图像再次进行降采样，直到达到所需的分辨率层级。
  - 这样就形成了一个金字塔状的层级结构，其中每个层级的图像都比上一层级的图像具有更低的分辨率。
  - 在每层进行高斯滤波器操作

  多分辨率金字塔的主要优势之一是可以在不同尺度下对图像进行分析。高层级的图像层级具有较低的分辨率，但能够捕捉到图像的整体特征和结构信息；而低层级的图像层级具有较高的分辨率，能够提供更多的细节信息。因此，通过在不同层级上对图像进行处理，可以获得更全面和准确的分析结果。

- **尺度空间差分金字塔**： 尺度空间差分金字塔是基于高斯金字塔的构建方法。它通过计算高斯金字塔相邻层之间的差分图像来获取尺度空间的特征。这样做可以捕捉到图像中的细节信息，而较高尺度的层级可以揭示出图像中的整体结构。通过在不同层级上进行差分操作，可以凸显出图像中的边缘、角点等局部结构。具体步骤如下：

  - 构建高斯金字塔，并对每一层进行高斯平滑。
  - 对相邻两层图像进行差分操作，得到差分图像。
  - 重复以上步骤，直到达到预定的尺度层数。



**DOG定义：**

**DoG空间极值检测**

为了寻找尺度空间的极值点，每个像素点要和其图像域（同一尺度空间）和尺度域（相邻的尺度空间）的所有相邻点进行比较，当其大于（或者小于）所有相邻点时，该点就是极值点。如下图所示，中间的检测点要和其所在图像的`3×3`邻域`8`个像素点，以及其相邻的上下两层的`3×3`领域`18`个像素点，共`26`个像素点进行比较。



#### 2.2 关键点定位

这些候选关键点是DOG空间的局部极值点，而且这些极值点均为离散的点，精确定位极值点的一种方法是：对尺度空间DoG函数进行曲线拟合，计算其极值点，从而实现关键点的精确定位。



#### 2.3 消除边界响应

接下来得到了这些极值点具体位置之后，我们还需要对位置进行一些过滤，这里有一个方法就是**消除边界响应**。因为之前我们通过高斯滤波器对图像进行各种操作，可能会增加一些边界的响应，此时我们需要将其消除掉。

在这里啊，修正方法和我们之前介绍边缘检测类似，当一个特征值大，一个特征值小的时候，它就是边界，这里我们定义了一个和一个。=较大特征值，=较小特征值，组成一个矩阵，具体如下：



#### 2.4 代码示例

下面我们看如何在opencv中实现SIFT特征变换

*注意：*新版本的opencv不能直接调用，需要降版本为3.4.1，安装命令如下；

```sh
pip install opencv-python==3.4.1.15
pip install opencv-contrib-python==3.4.1.15
```

下面我们来看具体代码：

首先读取图片，这里我们还是使用之前的**小狗洋气图片**

```python
import cv2
import numpy as np

img = cv2.imread('yangqi.jpg')
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#灰度图
```

**得到关键点:**

接下来调用`xfeatures2d.SIFT_create()函数`初始化SIFT 检测器对象，然后使用`detect()`函数检测关键点

```python
sift = cv2.xfeatures2d.SIFT_create()
kp = sift.detect(gray, None)#得到特征点

img = cv2.drawKeypoints(gray, kp, img) #绘制特征点

cv2.imshow('drawKeypoints', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

**计算特征**:

接下来使用`sift.compute()`函数计算关键的及其对应的特征

```python
kp, des = sift.compute(gray, kp)
```

- `kp`：关键点
- `des`：每一个关键点对应的特征

接下来我们来看一下他们的纬度

```python
print(np.array(kp).shape) #kp是一个列表，需要转换成ndarray
print(des.shape)
(605,)
(605, 128)
```

结果表示我们一共得到了605个关键点，每个关键点是一个128维的向量。

## 3.3 SURF特征检测与描述



## 3.4 FAST特征检测



## 3.5 ORB特征检测与描述
