# 第七章:高级数据结构

## 7.1 图论算法

## 7.2 字典树 (Trie)

Trie 树（又叫“前缀树”或“字典树”）是一种用于快速查询“某个字符串/字符前缀”是否存在的数据结构。

- 根节点（Root）不包含字符，除根节点外的每一个节点都仅包含一个字符；
- 从根节点到某一节点路径上所经过的字符连接起来，即为该节点对应的字符串；
- 任意节点的所有子节点所包含的字符都不相同；



**字典树非常耗费内存**。

### 字典树的查找

1. 每次从根结点开始搜索；
2. 获取关键词的第一个字符，根据该字符选择对应的子节点，转到该子节点继续检索；
3. 在相应的子节点上，获取关键词的第二个字符，进一步选择对应的子节点进行检索；
4. 以此类推，进行迭代过程；
5. 在某个节点处，关键词的所有字母已被取出，则读取附在该节点上的信息，查找完成。

每次查询时，如果要查询的字符串长度是 k，那我们只需要比对大约 k 个节点，就能完成查询操作。跟原本那组字符串的长度和个数没有任何关系。所以说，构建好 Trie 树后，在其中查找字符串的时间复杂度是 O(k)，k 表示要查找的字符串的长度。

### 字典树的应用场景

在一组字符串中查找字符串，Trie 树实际上表现得并不好。它对要处理的字符串有及其严苛的要求。

第一，字符串中包含的字符集不能太大。我们前面讲到，如果字符集太大，那存储空间可能就会浪费很多。即便可以优化，但也要付出牺牲查询、插入效率的代价。

第二，要求字符串的前缀重合比较多，不然空间消耗会变大很多。

第三，如果要用 Trie 树解决问题，那我们就要自己从零开始实现一个 Trie 树，还要保证没有 bug，这个在工程上是将简单问题复杂化，除非必须，一般不建议这样做。

第四，我们知道，通过指针串起来的数据块是不连续的，而 Trie 树中用到了指针，所以，对缓存并不友好，性能上会打个折扣。

在一组字符串中查找字符串，Trie 树实际上表现得并不好。它对要处理的字符串有及其严苛的要求。

在一组字符串中查找字符串，Trie 树实际上表现得并不好。它对要处理的字符串有及其严苛的要求。

（1）自动补全

（2）拼写检查

（3）IP 路由 (最长前缀匹配)

使用 Trie 树的最长前缀匹配算法，Internet 协议（IP）路由中利用转发表选择路径。

（4）T9 (九宫格) 打字预测

（5）单词游戏

Trie 树可通过剪枝搜索空间来高效解决 Boggle 单词游戏

## 7.3 并查集 (Disjoint Set)

## 7.4 布隆过滤器 (Bloom Filter)



## 7.5 哈夫曼树 (Huffman Tree)

### 哈夫曼树



结点的权： 有某种现实含义的数值（如：表示结点的重要性等）
结点的带权路径长度  从树的根到该结点的路径长度（经过的边数）与该结点权的乘积

树的带权路径长度  树中所有叶结点的带权路径长度之和（WPL，Weighted Path Length）                               

在含有n个带权叶结点的二义树中，其中带权路径长度（WPL）最小的二义树称为哈夫曼树，也称最优二树

#### 哈夫曼数的构造

给定n个权值分别为wiwzw的结点，构造哈天曼树的算法描述如下：
1）将这n个结点分别作为n棵仅含一个结点的二叉树，构成森林F。
2）构造一个新结点，从F中选取两棵根结点权值最小的树作为新结点的左、右子树，并且将新结点的权值置为左、右子树上根结点的权值之和。
3）从F中删除刚才选出的两棵树，同时将新得到的树加入F中。
4）重复步骤2）和3），直至F中只剩下一树为止。



特点

1）每个初始结点最终都成为叶结点，且权值越小的结点到根结点的路径长度越大
2）哈夫曼树的结点总数为2n-1
3）哈天曼树中不存在度为1的结点。
4 哈天曼树并不唯一，但WPL必然相同且为最优



#### 哈夫曼编码

固定长度编码一每个字符用相等长度的二进制位表示

可变长度编码一一允许对不同字符用不等长的二进制位表示

若没有一个编码是另一个编码的前，则称这样的编码为前编码
有哈夫曼树得到哈曼编码   字符集中的每个字符作为一个叶子结点  各个字符出现的频度作为结点的权值，根据之前介绍的方法构造哈夫曼树

## 7.6 AVL树

**AVL 树**是带有平衡条件的二叉查找树，和红黑树相比，它是严格的平衡二叉树，平衡条件必须满足（所有节点的左右子树高度差不超过 1）。不管我们是执行插入还是删除操作，只要不满足上面的条件，就要通过旋转来保持平衡，而旋转是非常耗时的。

### 性质

AVL 树是二叉平衡查找树，所以继承了二叉查找树的性质，同时具有平衡属性：

- 任意节点左子树上的节点值比该节点小，右子树上的节点值比该节点大
- 左右子树高度之差的绝对值不能超过 1（当该值为 2 时表示平衡树失去了平衡）

节点的 `平衡因子` 是它的左子树的高度减去它的右子树的高度。带有平衡因子 1、0 或 -1 的节点被认为是平衡的。带有平衡因子 -2 或 2 的节点被认为是不平衡的，并需要重新平衡这个树。平衡因子可以直接存储在每个节点中，或从可能存储在节点中的子树高度计算出来。

距离插入节点最近的，且平衡因子的绝对值不大于 1 的节点为根的子树，我们称为最小不平衡子树

### 平衡调整

平衡二叉树的构建过程基于二叉查找树的构建过程，在插入节点的过程中，一旦出现不平衡现象（即某节点的平衡因子大于 1 或小于 -1），就需要找出 `最不平衡子树`，进行平衡调整，也叫 `旋转` 操作，调整最小不平衡子树中各节点的链接关系，使之称为新的平衡子树。旋转的过程就好比一条扁担出现一头重一头轻的现象，若能将扁担的支撑点改变，扁担两头就平衡了。

有四种情况可能导致二叉查找树不平衡，分别为：

1. LL：插入一个新节点到根节点的左子树（Left）的左子树（Left），导致根节点的平衡因子由 1 变为 2
2. RR：插入一个新节点到根节点的右子树（Right）的右子树（Right），导致根节点的平衡因子由 -1 变为 -2
3. LR：插入一个新节点到根节点的左子树（Left）的右子树（Right），导致根节点的平衡因子由 1 变为 2
4. RL：插入一个新节点到根节点的右子树（Right）的左子树（Left），导致根节点的平衡因子由 -1 变为 -2

> 这里指的根节点指的是 `最小不平衡子树` 的根节点，而非整棵树的根节点。

针对四种种情况可能导致的不平衡，可以通过旋转使之变平衡。有两种基本的旋转：

- 左旋转：将根节点旋转到（根节点的）右子节点的左子节点位置
- 右旋转：将根节点旋转到（根节点的）左子节点的右子节点位置

以上四种情况分别对应不同的不平衡情况，其中 LL 和 RR 只需要进行一次旋转即可重获平衡，而 LR 和 RL 则需要两次旋转。每种类型可以细分为三种情况，总共 12 种情况。

平衡调整的秘笈：

1. 属性克制（分类）：找插入新节点后 **失去平衡的最小子树**
2. 落井下石（右旋、左旋）
3. 谋权、篡位、变节（RL、LR）

#### LL 左左

第 1、2 种情况，`左左` 表示最小不平衡子树的根节点左子节点的左子节点是新插入节点的父节点

第 3 种情况，左左表示最小不平衡子树的根节点左子节点的左子节点是新插入的节点

![LL型平衡调整](https://tsejx.github.io/data-structure-and-algorithms-guidebook/static/avl-tree-ll.770bbe1b.jpg)

当出现上图情况一、二的时候：

1. 最小不平衡子树的根节点（图例中的节点 A）就带着它的子树，占据了该根节点的 `左子节点的右子节点`
2. 然后把原来的节点（节点 E）嫁接在该节点（节点 A）上。

当出现上图情况三的时候，只需要将最小不平衡子树的根节点变为它的子节点的右子节点即可。

#### RR 右右

和 LL 类似：

![RR型平衡调整](https://tsejx.github.io/data-structure-and-algorithms-guidebook/static/avl-tree-rr.ff46e413.jpg)

当出现上图情况一、二的时候：

1. 最小不平衡子树的根节点（图例中的节点 A）就带着它的子树，占据了该根节点的 `右子节点的左子节点`
2. 然后把原来的节点（节点 D）嫁接在该节点（节点 A）上。

当出现上图情况三的时候，只需要将最小不平衡子树的根节点变为它的子节点的左子节点即可。

#### LR 左右

![LR型平衡调整](https://tsejx.github.io/data-structure-and-algorithms-guidebook/static/avl-tree-lr.971a4778.jpg)

#### RL 右左

![RL型平衡调整](https://tsejx.github.io/data-structure-and-algorithms-guidebook/static/avl-tree-rl.89841327.jpg)

#### 平衡调整总结

当 LL 或 RR 时：

1. 只需要旋转一次，旋转方向与类型名称相反，也就是 LL 右旋、RR 左旋
2. 步骤一：最小不平衡子树的根节点替换掉位于它整下方的，它的子节点的子节点（落井）
3. 步骤二：然后将被替换掉的节点接到它的非空子节点上（下石）
4. 调整后的子树的根节点一定是最小不平衡子树高度更高一边的左子节点

当 LR 或 RL 时：

1. 需要旋转两次，旋转方向和顺序与类型名称相同，也就是 LR 先左旋后右旋，RL 先右旋后左旋
2. 步骤一：新增节点的父节点，先抛弃它的子节点，安插在根节点和根节点的左子节点之间（谋权）
3. 步骤二：然后将根节点变为它的空侧的子节点（篡位），然后将原新增的节点（就是被抛弃的子节点），`变换原来的方向` 嫁接在新根节点的子节点上（变节）
4. 调整后的子树的根节点一定是新增节点的父节点，所以称之为谋权篡位

### 特点

AVL 树本质上还是一棵二叉搜索树，它的特点是：

- AVL 树是一棵二叉搜索树
- AVL 树的左右子节点也是 AVL 树
- AVL 树拥有二叉搜索树的所有基本特点
- 每个节点的左右子节点的高度之差的绝对值最多为 1，即平衡因子为范围为 `[-1,1]`

### 操作

AVL 树的基本操作是旋转，有四种旋转方式，分别为：左旋转，右旋转，左右旋转（先左后右），右左旋转（先右后左），实际上，这四种旋转操作两两对称，因而也可以说成两类旋转操作。

定义 AVL 树：

```js

```

#### 属性定义

```js

```

定义每棵树的平衡状态：

```js

```

#### 左旋转

```js

```

#### 右旋转

```js

```

#### 插入操作

1. 先判断边界问题，当根节点为空时，创建新节点
2. 根据目标节点索引大小，递归左右子树，若索引相同则不插入新元素
3. 更新节点高度后，根据当前节点子树的平衡状态进行处理

```js

```

#### 删除操作

1. 先判断边界问题，当根节点为空时，创建新节点
2. 根据目标节点索引大小，递归左右子树，若索引相同则不插入新元素
3. 更新节点高度后，根据当前节点子树的平衡状态进行处理

```js

```

#### 查找操作

```js

```

#### 使用场景

AVL 树适合用于插入删除次数比较少，但查找多的情况。

也在 Windows 进程地址空间管理中得到了使用

旋转的目的是为了降低树的高度，使其平衡

## 7.7 树状数组 (Fenwick Tree)

## 7.8 线段树 (Segment Tree)

## 7.9 跳表

对于一个有序数组，可以使用高效的二分查找法，其时间复杂度为 `O(log n)`。

但是，即使是有序的链表，也只能使用低效的顺序查找，其时间复杂度为 `O(n)`。

如何提高链表的查找效率呢？

我们可以对链表加一层索引。具体来说，可以每两个结点提取一个结点到上一级，我们把抽出来的那一级叫作**索引**或**索引层**。索引节点中通过一个 down 指针，指向下一级结点。通过这样的改造，就可以支持类似二分查找的算法。我们把改造之后的数据结构叫作**跳表**（Skip list）。



随着数据的不断增长，一级索引层也变得越来越长。此时，我们可以为一级索引再增加一层索引层：二级索引层。



随着数据的膨胀，当二级索引层也变得很长时，我们可以继续为其添加新的索引层。**这种链表加多级索引的结构，就是跳表**。



### 跳表的时间复杂度

在一个具有多级索引的跳表中，第一级索引的结点个数大约就是 `n/2`，第二级索引的结点个数大约就是 `n/4`，第三级索引的结点个数大约就是 `n/8`，依次类推，也就是说，第 `k` 级索引的结点个数是第 `k-1` 级索引的结点个数的 `1/2`，那第 k 级索引结点的个数就是 `n/(2k)`。所以**跳表查询数据的时间复杂度就是 `O(logn)`**。

### 跳表的空间复杂度

比起单纯的单链表，跳表需要存储多级索引，肯定要消耗更多的存储空间。

假设原始链表大小为 n，那第一级索引大约有 n/2 个结点，第二级索引大约有 n/4 个结点，以此类推，每上升一级就减少一半，直到剩下 2 个结点。如果我们把每层索引的结点数写出来，就是一个等比数列。

```text
索引节点数 = n/2 + n/4 + n/8 … + 8 + 4 + 2 = n-2
```

所以，跳表的空间复杂度是 `O(n)`。

跳表的存储空间其实还有压缩空间。比如，我们增加索引节点的范围，由“每两个节点抽一个上级索引节点”改为“每五个节点抽一个上级索引节点”，可以显著节省存储空间。

实际上，在软件开发中，我们不必太在意索引占用的额外空间。在讲数据结构和算法时，我们习惯性地把要处理的数据看成整数，但是在实际的软件开发中，原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，所以当对象比索引结点大很多时，那索引占用的额外空间就可以忽略了。

### 跳表的操作

跳表是一种各方面性能都比较优秀的**动态数据结构**，可以支持快速的插入、删除、查找操作，写起来也不复杂，甚至可以替代红黑树（Red-black tree）。

#### 高效的动态插入和删除

跳表不仅支持查找操作，还支持动态的插入、删除操作，而且插入、删除操作的时间复杂度也是 `O(logn)`。

![img](https://raw.githubusercontent.com/dunwu/images/master/snap/20220323155933.png)

- **插入操作**：对于纯粹的单链表，需要遍历每个结点，来找到插入的位置。但是，对于跳表来说，我们讲过查找某个结点的的时间复杂度是 `O(log n)`，所以这里查找某个数据应该插入的位置，方法也是类似的，时间复杂度也是 `O(log n)`。
- **删除操作**：如果这个结点在索引中也有出现，我们除了要删除原始链表中的结点，还要删除索引中的。因为单链表中的删除操作需要拿到要删除结点的前驱结点，然后通过指针操作完成删除。所以在查找要删除的结点的时候，一定要获取前驱结点。当然，如果我们用的是双向链表，就不需要考虑这个问题了。

### 跳表索引动态更新

当我们不停地往跳表中插入数据时，如果我们不更新索引，就有可能出现某 2 个索引结点之间数据非常多的情况。极端情况下，跳表还会退化成单链表。

![img](https://raw.githubusercontent.com/dunwu/images/master/snap/20220323161942.png)

如红黑树、AVL 树这样的平衡二叉树，是通过左右旋的方式保持左右子树的大小平衡，而跳表是通过随机函数来维护前面提到的“平衡性”。

当我们往跳表中插入数据的时候，我们可以选择同时将这个数据插入到部分索引层中。如何选择加入哪些索引层呢？可以通过一个随机函数，来决定将这个结点插入到哪几级索引中，比如随机函数生成了值 K，那我们就将这个结点添加到第一级到第 K 级这 K 级索引中。

### 为什么需要跳表

跳表是一种动态数据结构，支持快速的插入、删除、查找操作，时间复杂度都是 `O(logn)`。

跳表的空间复杂度是 `O(n)`。不过，跳表的实现非常灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。虽然跳表的代码实现并不简单，但是作为一种动态数据结构，比起红黑树来说，实现要简单多了。所以很多时候，我们为了代码的简单、易读，比起红黑树，我们更倾向用跳表。

### 跳表的应用场景

经典实现：Redis 的 Sorted Set、JDK 的 `ConcurrentSkipListMap` 和 `ConcurrentSkipListSet` 都是基于跳表实现。

为什么 Redis 要用跳表来实现有序集合，而不是红黑树？

Redis 中的有序集合支持的核心操作主要有下面这几个：

- 插入一个数据；
- 删除一个数据；
- 查找一个数据；
- 按照区间查找数据（比如查找值在 [100, 356] 之间的数据）；
- 迭代输出有序序列。

其中，插入、删除、查找以及迭代输出有序序列这几个操作，红黑树也可以完成，时间复杂度跟跳表是一样的。但是，按照区间来查找数据这个操作，红黑树的效率没有跳表高。
